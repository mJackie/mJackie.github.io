<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Hadoop 笔记 | Jackie Liu&#39;s Blog</title>
  
    <link rel="alternate" href="/atom.xml" title="Jackie Liu&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/logo.jpg">
  
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.opacity.css" media="screen" type="text/css">
  
    <link rel="stylesheet" href="/css/code.css" media="screen" type="text/css">
  

</head>
</html>

 <body class="archive category category-think category-1">
  <div id="page">
   <hgroup id="ctn_header">
    <div id="title">
     <div id="site-title"><a href="/" >Jackie Liu&#39;s Blog</a></div>
     <div id="site-description">Born to be proud</div>
    </div>
    <div id="title_r">
     <a href="http://weibo.com/liu133" title="SinaWeibo" ><button class="tr_weibo"></button></a> 
     <a href="http://github.com/mJackie" title="Github"><button class="tr_github"></button></a> 
     
     	<a href="/atom.xml"><button class="tr_rss"></button></a> 
     
     <span id="tr_clear"></span>
     <!--form id="tr_s_f" method="get" action=""> 
      <input id="tr_search" name="s" placeholder="" size="10" type="text" />
     </form-->
    </div>
    <div class="clearfix"></div> 
   </hgroup>
   <div id="float">
    <a href="/" rel="home"><img id="logo" src="/img/logo.jpg" /></a>
    <nav id="nav" role="navigation">
     <div>
      <ul class="menu">
        
          <li><a href="/categories/Tech">Tech</a></li>
        
          <li><a href="/categories/Life">Life</a></li>
        
      </ul>
     </div>
    </nav>
    <nav id="next">
     <div>
      <ul class="menu">
        
          <li><a href="/AboutMe">About Me</a></li>
        
      </ul>
     </div>
    </nav>
   </div>
   <div id="ctn">
    <div id="content"> 
	

		<article id="post-hadoop" class="article post article-type-post" itemscope="" itemprop="blogPost">
  <hgroup class="post_hctn"> 
    <div class="post_time">
        <div class="post_t_d">
         3/24
        </div>
        <div class="post_t_u">
         2018
        </div>
    </div>
   <div class="post_h_l"> 
   <h2 class="post_h"><a href="/Tech/cjr3allos001n6dkfhcfxep2b/">
    
      Hadoop 笔记
    
    </a></h2>
    <div class="post_tag"> 
      <a class="article-category-link" href="/categories/Tech/">Tech</a>
      <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/大数据/">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/计算广告/">计算广告</a></li></ul>
    </div>
   </div> 
  </hgroup>
  <div class="post_t">
    <p>      
       </p><h2 id="Hadoop基础及演练"><a href="#Hadoop基础及演练" class="headerlink" title="Hadoop基础及演练"></a>Hadoop基础及演练</h2><h3 id="Hadoop-优点"><a href="#Hadoop-优点" class="headerlink" title="Hadoop 优点"></a>Hadoop 优点</h3><ul>
<li>高扩展</li>
<li>低成本</li>
<li>成熟的生态圈<blockquote>
<ul>
<li>HIVE 降低了Hadoop使用门槛，可以将SQL语句转化为Hadoop任务</li>
<li>HBase 是一个存储结构化数据的分布式数据库，放弃了事务特性，追求更高的特战，HBase提供数据的随机读写和实时访问，实现了对表数据的读写功能</li>
<li>Zookeeper 监控Hadoop集群的一个状态，管理集群配置，维护节点间数据的一致性</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="Hadoop安装"><a href="#Hadoop安装" class="headerlink" title="Hadoop安装"></a>Hadoop安装</h3><ol>
<li>安装JDK</li>
<li>安装Hadoop</li>
<li><p>配置Hadoop</p>
<p>conf/start-all.sh</p>
<pre><code>jps 查看本地启动进程
</code></pre></li>
</ol>
<h3 id="HDFS-优点"><a href="#HDFS-优点" class="headerlink" title="HDFS 优点"></a>HDFS 优点</h3><ul>
<li>适合大文件存储，支持TB、PB级的数据存储，并有副本策略</li>
<li>可以构建在廉价的机器上，并有一定的容错和恢复机制</li>
<li>支持流式数据访问，一次写入，多次读取最高效</li>
</ul>
<h3 id="HDFS-缺点"><a href="#HDFS-缺点" class="headerlink" title="HDFS 缺点"></a>HDFS 缺点</h3><ul>
<li>不适合大量小文件存储</li>
<li>不适合并发写入，不支持文件随机修改</li>
<li>不支持随机读低延时的访问方式</li>
</ul>
<a id="more"></a>
<h3 id="HDFS-写流程"><a href="#HDFS-写流程" class="headerlink" title="HDFS 写流程"></a>HDFS 写流程</h3><ol>
<li>客户端向NameNode发起写数据请求</li>
<li>分块写入DataNode节点，DataNode自动完成副本备份</li>
<li>DataNode向NameNode汇报存储完成，NameNode通知客户端</li>
</ol>
<h3 id="HDFS-读流程"><a href="#HDFS-读流程" class="headerlink" title="HDFS 读流程"></a>HDFS 读流程</h3><ol>
<li>客户端向NameNode发起读数据请求</li>
<li>NameNode找出距离最近的DataNode节点信息</li>
<li>客户端从DataNode分块下载文件</li>
</ol>
<h3 id="HDFS-Shell命令"><a href="#HDFS-Shell命令" class="headerlink" title="HDFS Shell命令"></a>HDFS Shell命令</h3><p>很多命令和Linux是一致的<br>​<br>    ./hdfs dfs -help    #查看帮助文档<br>    hdfs dfs -ls /    #查看根目录<br>    hdfs dfs -du -h    #查看文件大小<br>    hdfs dfs -text #查看文件<br>    hdfs dfs -mkdir /test    #创建test目录<br>    hdfs dfs -copyFromLocal /home/hadoop/mk.txt /test/<br>    hdfs dfs -cat /test/mk.txt<br>    hdfs dfs -copyToLocal /test/mk.txt /home/hadoop/mk2.txt<br>    hdfs dfs -chmod 777 /test/mk.txt</p>
<h3 id="lzop"><a href="#lzop" class="headerlink" title="lzop"></a>lzop</h3><pre><code>//使用lzop命令解压并查看
lzop -cd xxx.lzo |more

//压缩命令：
lzop xxx.log （生成xxx.log.lzo）

//列出test.lzo中各个文件的压缩信息
lzop -l test.lzo 
</code></pre><h3 id="程序操作HDFS"><a href="#程序操作HDFS" class="headerlink" title="程序操作HDFS"></a>程序操作HDFS</h3><p>通过相应的API，调用相应的方法即可</p>
<h3 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h3><p>Hadoop 2.0 之后的资源管理器，移除了原有的JobTracker和TaskTracker,所有的MapReduce需要通过YARN进行调度。</p>
<ul>
<li>ResourceManager: 分配调度资源，启动监控ApplicationManager，监控NodeManager</li>
<li>ApplicationManager: 为MR程序申请资源，分配任务，负责数据切片，监控任务执行，容错</li>
<li>NodeManager: 管理单个节点的资源，处理ResourceManager，ApplicationManager的命令</li>
</ul>
<h3 id="MapReduce-编程模型"><a href="#MapReduce-编程模型" class="headerlink" title="MapReduce 编程模型"></a>MapReduce 编程模型</h3><ol>
<li>输入一个大的模型，通过Split之后，将其切分为多个分片。</li>
<li>Map阶段每个文件分片由单独的机器处理（需要编码）</li>
<li>Shuffle阶段.Map输入到Reduce输出的过程，涉及到网络传输</li>
<li>Reduce阶段将各个机器的结果汇总，并得到最终的结果（需要编码）</li>
</ol>
<p>Hadoop 1.x 默认block大小64M<br>Hadoop 2.x 默认block大小128M<br>可以在hdfs-site.xml中设置参数：dfs.block.size</p>
<h4 id="map任务个数"><a href="#map任务个数" class="headerlink" title="map任务个数"></a>map任务个数</h4><p>map任务个数是受多条件制约的，一般一个DataNode的map任务数量控制在10到100比较合适</p>
<ul>
<li>可增大mapred.map.tasks；减少map个数</li>
<li>可增大mapred.min.split.size</li>
<li>如果要减少map个数，但有很多小文件，可将小文件合并为大文件，再使用上条准则</li>
</ul>
<p>数据经过Map端输出后会进行网络混洗，经Shuffle后进入Reduce，在大数据量的情况下可能会造成巨大的网络开销。故可以在本地先按照key进行一轮排序与合并，在进行网络混洗，这个过程就是Combine.</p>
<p>图<br>partition任务,reduce任务,输出文件三者的数量总是相等的。所有数据默认会按照key值升序排序。</p>
<h4 id="reduce任务个数"><a href="#reduce任务个数" class="headerlink" title="reduce任务个数"></a>reduce任务个数</h4><p>reduce任务不像Map任务那样受多个因素制约,大数据情况下，reduce数量不宜过少</p>
<ul>
<li>可通过调节参数 mapred.reduce.tasks</li>
<li>可在代码中调用 job.setNumReduceTasks(int n)</li>
</ul>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>如何通过Hadoop存储小文件？<blockquote>
<p>Hadoop Archives 出现就是为了缓解大量小文件消耗NameNode内存的问题，HAR文件是通过在HDFS上构建一个分层文件系统来工作；使用SequenceFile，用文件名（filename）作为key，并且文件内容（file contents）作为value；可以通过Hbase开发一个对象存储服务;可以采用压缩、合并小文件的策略，例如设置文件输入类型为CombineFileInputFormat格式</p>
</blockquote>
</li>
<li>当有节点故障的时候，集群是如何继续提供服务的，如何读？如何写？</li>
<li>哪些是影响MapReduce性能的因素？</li>
</ol>
<h3 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h3><ul>
<li>高可靠，高性能，面向列，可伸缩，实时读写的<strong>分布式数据库</strong></li>
<li>利用HDFS作为其文件存储系统，支持MR程序读取数据</li>
<li>存储非结构化和半结构化数据</li>
<li>RowKey: 数据唯一标识，按字典排序</li>
<li>ColumnFamily: 列族，多个列的集合，最多不超过三个</li>
<li>TimeStamp: 支持多版本数据同时存在</li>
</ul>
<h3 id="HIVE"><a href="#HIVE" class="headerlink" title="HIVE"></a>HIVE</h3><p>show databases;<br>use database;<br>show tables;<br>desc table;<br>dfs -ls 目录；<br>! 操作系统命令<br>select * from gen_yp_show_log_det_hour limit 5;<br>source mysql.sql;<br>hive -S #进入静默模式</p>
<h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><ul>
<li><strong>基于内存计算</strong>的大数据并行计算框架</li>
<li>Spark是MapReduce的替代方案，兼容HDFS，Hive等数据源</li>
<li>抽象出分布式内存存储数据结构，弹性分布式数据集RDD</li>
<li>基于事件驱动，通过线程池复用线程提高性能</li>
</ul>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p><img src="/post_image/map-reduce.jpg" alt="image"></p>
<p>既可以直接编写相应JAVA处理程序，也可用Python等其他语言编写Map,Reduce处理过程，利用Hadoop进行执行</p>
<ol>
<li>编写 WordCount.java 程序</li>
<li><p>编译 WordCount.java</p>
<pre><code>javac -classpath -d
</code></pre></li>
<li><p>打包<br>jar -cvf wordcount.jar *.class</p>
</li>
<li>提交作业<br>hdfs dfs -copyFromLocal<pre><code>hadoop jar
yarn logs -applicationId xxxx    //查看日志
</code></pre><h3 id="Hadoop分布式缓存"><a href="#Hadoop分布式缓存" class="headerlink" title="Hadoop分布式缓存"></a>Hadoop分布式缓存</h3>在执行MapReduce时，可能Mapper之间需要共享一些信息，如果信息量不大，可以将其从HDFS加载到内存中，这就是Hadoop分布式缓存机制</li>
</ol>
<p>加载到内存发生在Job执行之前，每个从节点各自都缓存一份相同的共享数据。如果数据量过大，可以将其分批缓存，重复执行作业。</p>
<ol>
<li><p>在main方法中加载共享文件的HDFS路径，路径可以是目录也可以是文件。可以在路径末尾追加“#”+别名，在map阶段可以使用该别名</p>
<pre><code>String cache = &quot;hdfs://10.105.***.***:8020/cache/file&quot;;    //目录或文件
cache = cache + &quot;#myfile&quot;;     //myfile是文件别名
job.addCacheFile(new Path(cache).toUri(),conf)    //添加到job设置
</code></pre></li>
<li><p>在Mapper类或Reducer的setup方法中，用输入流获取分布式缓存中的文件</p>
<p>//该方法只执行一次，在map方法循环之前</p>
<pre><code>protected void setup（Context context） throws IOException,InterruptedException{
    FileReader reader = new FileReader(&quot;myfile&quot;);
    BufferedReader br = new BufferedReader(reader);
     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">### Mac Eclipse Hadoop-plus配置</span><br><span class="line">将插件jar包放在Eclipse的 **dropins** 文件夹下</span><br><span class="line">- 查看端口</span><br><span class="line">&gt; hdfs端口号在：```$HADOOP_HOME/conf/core-site.xml中</span><br></pre></td></tr></table></figure>
</code></pre></li>
</ol>
<blockquote>
<p>mr端口号在：<code>$HADOOP_HOME/conf/mapred-site.xml中</code></p>
</blockquote>
<pre><code>dfs.datanode.ipc.address  JobTracker端口，默认50020
fs.defaultFS    HDFS端口，默认8020
</code></pre><h3 id="Python-MapReduce"><a href="#Python-MapReduce" class="headerlink" title="Python MapReduce"></a>Python MapReduce</h3><pre><code> cat 0318part-00001|python mapper.py 
cat 0318part-00001|python mapper.py |sort -k1,1|python reducer.py 
</code></pre><h3 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h3><pre><code>//查看日志
yarn logs -applicationId appid
//查看状态
yarn application -status
//杀掉任务
yarn application -kill appid
</code></pre>
    <p></p>
  </div>











    
    <ul class="post-near">
      
        <li>上一篇: <a href="/Tech/cjr3alloi000x6dkf1snrl6vg/">            
            
              Spark 笔记
            
          </a>
        </li>
      
      
        <li>下一篇: <a href="/Life/cjr3allpd002y6dkfg830gezz/">            
            
              实习面试
            
          </a>
        </li>
      
    </ul>
    
</article>


    </div>
   </div>
   

   <div id="link" style="display:block">
    <div id="link_content">
     <h3 id="link_h">友情链接</h3> 
     
      <a href="https://mjackie.github.io">Jackie Liu&#39;s Blog</a>
     
    </div>
   </div>
   
   <footer id="footer" role="contentinfo">
     Power by <a href="#" style=" display:inline-block ">Jackie Liu</a>
   </footer>
    <script rel="stylesheet" src="/js/prettify.js" type="text/javascript"></script>
    <script type="text/javascript">
	    window.onload = function () {
	        change();
	        //代码高亮开始
	        var pre = document.getElementsByTagName('pre');
	        for(i=0,l=pre.length;i<l;i++) 
	          pre[i].className += " prettyprint linenums";
	        prettyPrint();
	    }

      function change(){
        var i = Math.random();  //产生0-1之间的随机数
		i = i * 10;             //用随机数乘以10
		i = Math.round(i);      //取整
		var path = "";
		switch(i){
		  case 0: path = "/img/background0.jpg";break;    //图片位置
		  case 1: path = "/img/background1.jpg";break;
		  case 2: path = "/img/background2.jpg";break;
		  case 3: path = "/img/background3.jpg";break;
		  case 4: path = "/img/background4.jpg";break;
		  case 5: path = "/img/background5.jpg";break;
		  case 6: path = "/img/background6.jpg";break;
		  case 7: path = "/img/background7.jpg";break;
		  case 8: path = "/img/background8.jpg";break;
		  case 9: path = "/img/background9.jpg";break;
		  case 10: path = "/img/background10.jpg";break;
/*      case 0: path = "http://ogzyt1sa2.bkt.clouddn.com/background0.jpg";break;    //图片位置
      case 1: path = "http://ogzyt1sa2.bkt.clouddn.com/background1.jpg";break;
      case 2: path = "http://ogzyt1sa2.bkt.clouddn.com/background2.jpg";break;
      case 3: path = "http://ogzyt1sa2.bkt.clouddn.com/background3.jpg";break;
      case 4: path = "http://ogzyt1sa2.bkt.clouddn.com/background4.jpg";break;
      case 5: path = "http://ogzyt1sa2.bkt.clouddn.com/background5.jpg";break;
      case 6: path = "http://ogzyt1sa2.bkt.clouddn.com/background6.jpg";break;
      case 7: path = "http://ogzyt1sa2.bkt.clouddn.com/background7.jpg";break;
      case 8: path = "http://ogzyt1sa2.bkt.clouddn.com/background8.jpg";break;
      case 9: path = "http://ogzyt1sa2.bkt.clouddn.com/background9.jpg";break;
      case 10: path = "http://ogzyt1sa2.bkt.clouddn.com/background10.jpg";break;*/
    }
    document.body.style.backgroundImage = "URL("+path+")";  //显示对应的图片
    }

  </script>
  
  </div>
 </body>
</html>